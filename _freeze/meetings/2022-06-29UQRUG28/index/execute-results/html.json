{
  "hash": "3fcb2b032978fc0b58e1db27d3c9445e",
  "result": {
    "markdown": "---\ntitle: UQRUG 28\ndate: '2022-06-29'\ncategories: meeting\n---\n\n\n\n\n### 2022-06-29: UQRUG 28\n\n#### Attendees\n\n* **St√©phane**: Library | here to help and say goodbye\n* **Chris**: Civil Engineering - Transport | just tagging along\n* **Luke**: Library | here to help and say hello\n* **Olalekan** Biological Sciences | here to say hello...\n\n\n#### Topics discussed and code\n\n##### Iterating instead of using repetitive code\n\nThe trick here is to:\n\n1. Encapsulate the repetitive code into a function, exposing the things that are likely to change as arguments\n2. Create a vector of values (or several)\n3. Use a for loop, or an `apply()` function, or a `map()` function (from purrr) to map the function to each element\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# iterating\n\n?mean\n# custom function\ncustom_mean <- function (numbers, trim_ratio) {\n  # process the data\n  my_mean <- mean(x = numbers, trim = trim_ratio, na.rm = TRUE)\n  # save the it as file\n  saveRDS(my_mean, file = paste0(numbers[1], trim_ratio, \".rds\"))\n}\n\n# use the function\ncustom_mean(c(1,5,NA), 0.2)\n\n# iterate\nlist_to_iterate_on <- list(c(1,5,NA),\n     c(1,4,6,8),\n     c(1,2,7,9,NA))\n\ntrim_ratios <- c(0.2, 0.7, 0.1)\n\nlibrary(purrr)\n# alternative to apply functions or for loops\nmap2(list_to_iterate_on, trim_ratios, custom_mean)\n\n# pmap(): construct a dataframe of all combinations,\n# with each column containing the argument values to use\n\n# construct the dataframe of all combinations\nanimal <- c(\"magpie\", \"pelican\", \"ibis\")\ntreatment <- c(\"dry food\", \"sludge\", \"grain\")\n# only three rows\nexperiment <- data.frame(animal, treatment)\n# all combinations\nlibrary(tidyr)\nall_combinations <- expand(experiment, animal, treatment)\n```\n:::\n\n\n##### List files\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# listing files\nlist.files() # all files in working directory\nonly_rds <- list.files(pattern = \"rds\")\nonly_rds <- list.files(\"analysis\", \"rds\")\nonly_rds\n# full path (from working directory)\nonly_rds <- list.files(\"analysis\", \"rds\", full.names = TRUE)\nonly_rds\n```\n:::\n\n\n##### Remove file extension from path\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# remove file extension from path\nlibrary(stringr)\nstr_replace(\"filename.txt\", \".txt\", \"\")\n```\n:::\n\n\n##### Extract information from filenames\n\nUsing the tidyverse and pdftools for preparing PDF text before analysis with quanteda. pdftools was used for its specific ability to return the page numbers of the pdfs.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pdftools)\nlibrary(tidyverse)\n\n# create a list of the PDF file paths\nmyfiles <- list.files(path = \"./pdfs\", pattern = \"*.pdf\", all.files = FALSE,\n                      full.names = TRUE, recursive = TRUE,\n                      ignore.case = FALSE, include.dirs = TRUE, no.. = FALSE)\n\n# Function to import each pdf file, and place the text in a dataframe\nimport_pdf <- function(k){\n    # turn the pdf into a text list each page will become a row\n  pdf.text <- pdftools::pdf_text(k)\n    # flatten the list\n  pdf.text<-unlist(pdf.text)\n  pdfdf <- data_frame(pdf.text)\n    # turn the list into a dataframe, extracting the year from the path and using the separate function to extract the state from the path\n  data_frame(pdf.text) %>%\n    mutate(year = str_extract(k, \"[:digit:]{4}\") %>% as.integer(), pagenumber = row.names(pdfdf), filename = k) %>% \n    separate(filename, c(NA,NA,\"state\",NA), sep = \"/\")\n  \n}\n    # run the function on all pdf files\nall_pdfs<- map_dfr(myfiles, import_pdf)\n```\n:::\n\n\nSee the [quanteda tutorials](https://tutorials.quanteda.io/)\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}