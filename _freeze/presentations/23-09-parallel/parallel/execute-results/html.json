{
  "hash": "72a335d216c1ad86055c4dd1e2a6c081",
  "result": {
    "markdown": "---\ntitle: |\n <div style=\"color: #51247A;\">[Parallelization in R]{.underline}<br><span style=\"font-size: 0.6em;\"> <em>[parallel](https://rdocumentation.org/packages/parallel/versions/3.6.2)</em> and <em>[foreach](https://www.rdocumentation.org/packages/foreach/versions/1.5.2)</em></span></div>\nauthor:\n  - name: Raúl Riesco\n    orcid: 0000-0001-8257-7601\n    email: r.riescojarrin@uq.edu.au // raul.riescoj@usal.es\n    affiliations:\n      - name: Australian Centre for Ecogenomics // University of Salamanca\n        \ndate: 09/27/2023\ndate-format: long\nformat: \n  revealjs:\n    incremental: true   \n    controls: true\nlogo: img/UQlogo-Purple-rgb.png\neditor: visual\nexecute:\n  echo: true\n---\n\n\n## Why to parallelize\n\n\n::: {.cell}\n<style type=\"text/css\">\n.justify {\n  text-align: justify !important\n}\n</style>\n:::\n\n::: {.cell}\n<style type=\"text/css\">\n/* Define a CSS class for the smaller table */\n.small-table {\n  font-size: 60%; /* Reduce font size to make text smaller */\n  padding: 4px; /* Reduce cell padding for a compact layout */\n  margin: 0; /* Remove any margin */\n}\n</style>\n:::\n\n\n::: {.incremental} \nHave you ever noticed that RStudio never reaches 100% CPU usage even when running a very demanding task?\n\n-   R runs only on a single thread on the CPU by default\n\n-   Is it the most efficient way to run functions?\n\n    -   Independent operations\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    results <- rep(0,10)\n        \n    for(num in 1:10)\n      {\n        results[num]<-num^2\n      }\n    \n    results\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n     [1]   1   4   9  16  25  36  49  64  81 100\n    ```\n    :::\n    :::\n\n:::\n\n## Parallelization in R\n\nIt is possible to parallelize processes in R using specialized packages.\n\n[**parallel**]{.underline}\n\n-   Most used package\n-   Part of r-core.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parallel)\n```\n:::\n\n\n## Cores in our PC and management of clusters\n\n**Basic concepts**\n\n-   [Core]{.underline}: an individual processing unit within a CPU\n-   [Cluster]{.underline}: R background sessions that allows parallelization of processes.\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```{`r}  \nLoad the package\n  library(parallel)\n\nnumber of cores\n  cores<- detectCores()\n  \nmake cluster\n  clust <- makeCluster(cores)\n\n```\n:::\n\n::: {.column width=\"50%\"}\n```{`r}  \nstart created cluster\n  registerDoParallel(clust)\n  \nstatus of the clusters\n  showConnections()\n\nclose the cluster\n  stopCluster(cl = clust) \n  \n```\n:::\n\n::::\n\n\n## Methods of Paralleization\n\n::: justify\nThere are two main ways in which code can be parallelized, via **sockets** or via **forking**\n\n-   [**Socket approach**]{.underline}: launches a new version of R on each core\n-   [**Forking approach**]{.underline}: copies the entire current version of R and moves it to a new core\n:::\n\n## Socket pros and cons\n\n::: justify\n-   Pros\n    -   [Works on every OS.]{style=\"color:darkgreen\"}\n    -   [Each process on each node are 100% independent.]{style=\"color:darkgreen\"}\n-   Cons\n    -   [Each process is unique so it will be slower]{style=\"color:darkred\"}\n    -   [Variables and packages must be imported to the created cores.]{style=\"color:darkred\"}\n    -   [More complicated to implement.]{style=\"color:darkred\"}\n:::\n\n## Forking pros and cons[^6]\n\n::: justify\n-   Pros\n    -   [Faster.]{style=\"color:darkgreen\"}\n    -   [Not necessary to import the variables and packages.]{style=\"color:darkgreen\"}\n    -   [Relatively easier to implement.]{style=\"color:darkgreen\"}\n-   Cons\n    -   [Does NOT work on Windows]{style=\"color:darkred\"}\n    -   [Processes are not totally independent, and can cause weird behaviors when runned in RStudio .]{style=\"color:darkred\"}\n\n:::\n\n[^6]:Code in this session wont be optimized for forking. Check [mclapply()](https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html) for more info.\n\n## *parallel* and *apply*\n::: justify\n\n*parallel* is designed to work with functions, and it is analogous to the use of functions like *apply*, as well as its derivatives *lapply* and *sapply*\n\n::: small-table\n| *apply* | *parallel* | INPUT | OUTPUT |\n|---------|:-----|------:|------:|\n| apply      | parApply (parRapply, parCapply)[^1]|data.frame, matrix|vector, list, array|\n| sapply   | parSapply  |List, vector, data.frame|vector/matrix|\n| lapply  | parLapply   | List, vector, data.frame|list|\n: Equivalent functions to the apply family {.striped .hover}\n:::\n:::\n\n[^1]: parRapply, parCapply are *parallel* row and column apply functions for a matrix x; they may be slightly more efficient than parApply but do less post-processing of the result.\n\n## *foreach*\n*foreach* is a package designed for looping. It also allows to combine results in diferent formats. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(foreach)\nforeach(i=1:2) %do% exp(i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 2.718282\n\n[[2]]\n[1] 7.389056\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(foreach)\nforeach(i=1:2, .combine='c') %do% exp(i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.718282 7.389056\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(foreach)\nforeach(a=1:1000, b=rep(10, 2), .combine='c') %do% {a+b}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 11 12\n```\n:::\n:::\n\n## *foreach*[^2]\nBy itself, *foreach* do not parallelize, but it can be combined with *parallel* and *doParallel* to allow paralellization\n```{'r}\nlibrary(foreach)\nlibrary(parallel)\nlibrary(doParallel)\n\nclust <- makeCluster(2)\nregisterDoParallel(clust)\n\nforeach(i=1:2, .combine='c') %dopar% exp(i)\n\nstopCluster(cl = clust)\n```\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.718282 7.389056\n```\n:::\n:::\n[^2]:[.combine=]{.underline}: [**’c’**]{.underline}:concatenate into a vector, [**’cbind’**]{.underline} and [**’rbind’**]{.underline}: combine vectors into a matrix. [**Operators (’+’, ’\\*’)**]{.underline}: process numeric data\n\n\n## Example\nDetermine which numbers on a sample are primes\n\nFunction:\n```{'r}\nisprime <- function(num){ \n    prime=TRUE \n    i=2                         #I need to start from 2, as prime numbers can only be divided by 1 and themselves.\n    while(i<num){               #The while loop will continue running as long as the value of 'i' is less than the specified number\n      if ((num %% i) == 0){     #The '%%' operator calculates the remainder when our number is divided by 'i.' If the remainder is 0, it will terminate the loop\n        prime = FALSE \n        break \n      }\n      i <- i+1 \n    }\n    return(prime) \n  }\n```  \ndata (10,000 numbers):\n```{'r}\nlistnumbers <- sample(1:100000,10000)\n``` \n\n## *for*[^3]\n```{`r}\nprimes<- rep(T,10000)   \n\nfor(i in 1:length(listnumbers)){\n  primes[i] <- isprime(listnumbers[i])\n}\n\nresult<-data.frame(number=listnumbers, is_prime=primes)\n```  \n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Time difference of 5.308078 secs\"\n```\n:::\n:::\n[^3]:In this script, before actually doing the calculation, I explicitly created a vector with the same dimensions as the final result of the loop output. This is important not only because this particular function needs it, but because it allows a preallocation of memory, speding up the process. \n\n## *foreach*[^4]\n```{`r}\nlibrary(foreach)\n   \nprimes_fe <-foreach(i = 1:length(listnumbers), .combine=\"c\") %do% { \n                    isprime(listnumbers[i]) \n                    }\n\nresult_fe<-data.frame(number=listnumbers, is_prime=primes_fe)\n```\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Time difference of 6.629166 secs\"\n```\n:::\n:::\n[^4]: This method is more or less equivalent to for, but in this case is slower because it does not optimize memory preallocation. The main advantage of the forEach syntax is that is shorter and easier to read, which is why some developers prefer it over for. It also allows simple parallelization and a native combination of results that will be handy to reduce code length.\n\n\n## *foreach* parallelized\n```{`r}\nlibrary(parallel)\nlibrary(foreach)\nlibrary(doParallel)\n\ncores <- detectCores()                 \nclust <- parallel::makeCluster(cores)  \nregisterDoParallel(clust)  \n \nprimes_par_fe <- foreach(i = 1:length(listnumbers), .combine=\"c\") %dopar% { \nisprime(listnumbers[i]) \n}\n\nresult_par_fe<-data.frame(number=listnumbers, is_prime=primes_par_fe)\n\nparallel::stopCluster(cl = clust) \n\n```\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Time difference of 2.964536 secs\"\n```\n:::\n:::\n\n## *sapply* [^5]\n```{`r}\nprimes_sa <- sapply(listnumbers, isprime) \n\nresult_sa<-data.frame(number=listnumbers, is_prime=primes_sa)\n```\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Time difference of 5.478974 secs\"\n```\n:::\n:::\n[^5]: apply is more efficient than foreach because it does a memory preallocation step in the background\n\n## *parSapply*\n```{`r}\nlibrary(parallel)\n\ncores <- detectCores()     \nclust <- parallel::makeCluster(cores)\n\nprime_par_sa <- parSapply(clust, listnumbers, isprime)             \n\nresult_par_sa<-data.frame(number=listnumbers, is_prime=prime_par_sa)\n\nparallel::stopCluster(cl = clust) \n```\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Time difference of 1.725008 secs\"\n```\n:::\n:::\n\n## Has the processing time improved?\n\n::: {.cell}\n::: {.cell-output-display}\n![](parallel_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n",
    "supporting": [
      "parallel_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}